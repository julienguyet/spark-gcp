# Deploy a Spark cluster on GCP 
<div>
  <img src="https://github.com/devicons/devicon/blob/master/icons/googlecloud/googlecloud-original-wordmark.svg" title="GCP" alt="GCP" width="200" height="200"/>&nbsp;
   <img src="https://github.com/devicons/devicon/blob/master/icons/apachespark/apachespark-original-wordmark.svg" title="Spark" alt="Spark" width="200" height="200"/>&nbsp;
</div>

---

## 1. Introduction

In this tutorial we will see how we can deploy a Spark cluster on Google Cloud and how to use it to:
- Process large amount of data and extract insghts from this data :dna:
- Perform some Machine Learning Prediction job :robot:

Start by cloning this repository and once process is finished, please move to the next section.

---

## 2. Set up the GCP components

---

## 3. Run a job

Image for make submit_job:
<img width="536" alt="Screenshot 2024-05-20 at 15 41 54" src="https://github.com/julienguyet/spark-gcp/assets/55974674/071b3a31-ed1d-4cf4-82dc-9f3b0a8b7a9c">

Image for job running:
<img width="1048" alt="Screenshot 2024-05-21 at 13 17 46" src="https://github.com/julienguyet/spark-gcp/assets/55974674/813ffff6-c38e-49df-841e-4daf3ed1ce92">

Image for Bucket:
<img width="356" alt="Screenshot 2024-05-22 at 18 42 04" src="https://github.com/julienguyet/spark-gcp/assets/55974674/88bc3ad5-f386-4af0-9e5e-02b6d9d66ae1">
