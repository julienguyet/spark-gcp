{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:31:26 WARN Utils: Your hostname, Juliens-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.0.0.2 instead (on interface en0)\n",
      "24/05/22 16:31:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/22 16:31:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "                    .appName('App') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/julien/Documents/EPITA/S2/Spark/data/NYC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-12-01 00:19:51|  2021-12-01 00:37:01|            1.0|          9.3|       1.0|                 N|         138|         141|           1|       26.5| 4.25|    0.5|       7.6|        6.55|                  0.3|        45.7|                 2.5|       1.25|\n",
      "|       2| 2021-12-01 00:29:07|  2021-12-01 00:45:13|            2.0|         2.76|       1.0|                 N|         238|          42|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.8|                 2.5|        0.0|\n",
      "|       1| 2021-12-01 00:12:40|  2021-12-01 00:27:17|            0.0|          3.4|       1.0|                 N|         239|          74|           1|       13.5|  3.0|    0.5|       2.0|         0.0|                  0.3|        19.3|                 2.5|        0.0|\n",
      "|       1| 2021-12-01 00:10:18|  2021-12-01 00:19:20|            1.0|          1.3|       1.0|                 N|         148|          87|           1|        6.5|  3.0|    0.5|      2.05|         0.0|                  0.3|       12.35|                 2.5|        0.0|\n",
      "|       1| 2021-12-01 00:25:12|  2021-12-01 00:39:07|            1.0|          3.1|       1.0|                 N|         231|         246|           1|       12.5|  3.0|    0.5|       2.5|         0.0|                  0.3|        18.8|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Average Duration and Distance of rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration\n",
    "from pyspark.sql.functions import month, avg, unix_timestamp, dayofmonth, hour\n",
    "\n",
    "def analyze(spark, format=\"parquet\", gcs_input_path=None, gcs_output_path=None):\n",
    "    df = spark.read.format(format).load(gcs_input_path)\n",
    "\n",
    "    df_enriched = df.withColumn(\n",
    "        \"duration_time_in_minutes\",\n",
    "        (\n",
    "            unix_timestamp(df[\"tpep_dropoff_datetime\"])\n",
    "            - unix_timestamp(df[\"tpep_pickup_datetime\"])\n",
    "        )\n",
    "        / 60,\n",
    "    )\n",
    "\n",
    "    # Performs basic analysis of dataset\n",
    "    df_month = df_enriched.groupBy(\n",
    "        month(\"tpep_pickup_datetime\").alias(\"month\")).agg(\n",
    "        avg(\"duration_time_in_minutes\").alias(\"average_trip_time_in_minutes\")\n",
    "    ).orderBy(\"month\", ascending=True) \\\n",
    "    \n",
    "    df_month.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/month_analysis\")\n",
    "\n",
    "    df_day = df_enriched.groupBy(\n",
    "        dayofmonth(\"tpep_pickup_datetime\").alias(\"dayofmonth\")).agg(\n",
    "        avg(\"duration_time_in_minutes\").alias(\"average_trip_time_in_minutes\")\n",
    "    ).orderBy(\"dayofmonth\", ascending=True)\n",
    "\n",
    "    df_day.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/day_analysis\")\n",
    "\n",
    "    df_hour = df_enriched.groupBy(\n",
    "        hour(\"tpep_pickup_datetime\").alias(\"hour\")).agg(\n",
    "        avg(\"duration_time_in_minutes\").alias(\"average_trip_time_in_minutes\")\n",
    "    ).orderBy(\"hour\", ascending=True)\n",
    "\n",
    "    df_hour.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/hour_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'trip_distance'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"trip_distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trip distance\n",
    "\n",
    "def analyze(spark, format=\"parquet\", gcs_input_path=None, gcs_output_path=None):\n",
    "    df = spark.read.format(format).load(gcs_input_path)\n",
    "\n",
    "    df_enriched = df.withColumn(\n",
    "        \"distance_in_miles\",\n",
    "        (\n",
    "            df[\"trip_distance\"])\n",
    "        )\n",
    "\n",
    "    # Performs basic analysis of dataset\n",
    "    df_month = df_enriched.groupBy(\n",
    "        month(\"tpep_pickup_datetime\").alias(\"month\")).agg(\n",
    "        avg(\"trip_distance\").alias(\"average_trip_distance_in_miles\")\n",
    "    ).orderBy(\"month\", ascending=True) \\\n",
    "    \n",
    "    df_month.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/month_analysis\")\n",
    "\n",
    "    df_day = df_enriched.groupBy(\n",
    "        dayofmonth(\"tpep_pickup_datetime\").alias(\"dayofmonth\")).agg(\n",
    "        avg(\"trip_distance\").alias(\"average_trip_distance_in_miles\")\n",
    "    ).orderBy(\"dayofmonth\", ascending=True)\n",
    "\n",
    "    df_day.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/day_analysis\")\n",
    "\n",
    "    df_hour = df_enriched.groupBy(\n",
    "        hour(\"tpep_pickup_datetime\").alias(\"hour\")).agg(\n",
    "        avg(\"trip_distance\").alias(\"average_trip_distance_in_miles\")\n",
    "    ).orderBy(\"hour\", ascending=True)\n",
    "\n",
    "    df_hour.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/hour_analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Popular locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-12-01 00:19:51|  2021-12-01 00:37:01|            1.0|          9.3|       1.0|                 N|         138|         141|           1|       26.5| 4.25|    0.5|       7.6|        6.55|                  0.3|        45.7|                 2.5|       1.25|\n",
      "|       2| 2021-12-01 00:29:07|  2021-12-01 00:45:13|            2.0|         2.76|       1.0|                 N|         238|          42|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.8|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|PULocationID|pickup_count|\n",
      "+------------+------------+\n",
      "|         237|     1553554|\n",
      "|         236|     1424614|\n",
      "|         161|     1091329|\n",
      "|         132|     1025063|\n",
      "|         186|     1019650|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"NYC_data\")\n",
    "spark.sql(\"select PULocationID, COUNT(*) as pickup_count from NYC_data GROUP BY 1 ORDER BY 2 DESC LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|DOLocationID|drop_count|\n",
      "+------------+----------+\n",
      "|         236|   1434919|\n",
      "|         237|   1356518|\n",
      "|         161|   1001077|\n",
      "|         170|    920433|\n",
      "|         141|    902052|\n",
      "+------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select DOLocationID, COUNT(*) as drop_count from NYC_data GROUP BY 1 ORDER BY 2 DESC LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|DOLocationID|drop_count|\n",
      "+------------+----------+\n",
      "|         236|   1434919|\n",
      "|         237|   1356518|\n",
      "|         161|   1001077|\n",
      "|         170|    920433|\n",
      "|         141|    902052|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf, count, expr\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "df.groupBy(\"DOLocationID\") \\\n",
    "    .agg(count(\"*\").alias(\"drop_count\")) \\\n",
    "    .orderBy((\"drop_count\"), ascending = False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|PULocationID|drop_count|\n",
      "+------------+----------+\n",
      "|         237|   1553554|\n",
      "|         236|   1424614|\n",
      "|         161|   1091329|\n",
      "|         132|   1025063|\n",
      "|         186|   1019650|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pickups = df.groupBy(\"PULocationID\") \\\n",
    "    .agg(count(\"*\").alias(\"drop_count\")) \\\n",
    "    .orderBy((\"drop_count\"), ascending = False) \\\n",
    "    .limit(5)\n",
    "\n",
    "df_pickups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top pickups and drop locations\n",
    "\n",
    "def analyze(spark, format=\"parquet\", gcs_input_path=None, gcs_output_path=None):\n",
    "    df = spark.read.format(format).load(gcs_input_path)\n",
    "    \n",
    "    df_pickups = df.groupBy(\"PULocationID\") \\\n",
    "    .agg(count(\"*\").alias(\"drop_count\")) \\\n",
    "    .orderBy((\"drop_count\"), ascending = False) \\\n",
    "    .show(5)\n",
    "\n",
    "    df_pickups.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/top_pickup_locations\")\n",
    "\n",
    "    df_drops = df.groupBy(\"DOLocationID\") \\\n",
    "    .agg(count(\"*\").alias(\"drop_count\")) \\\n",
    "    .orderBy((\"drop_count\"), ascending = False) \\\n",
    "    .show(5)\n",
    "\n",
    "    df_drops.repartition(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .save(f\"{gcs_output_path}/top_drops_locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip percentage by trip:\n",
    "- Tip by locations\n",
    "- correlation between distance and tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-12-01 00:19:51|  2021-12-01 00:37:01|            1.0|          9.3|       1.0|                 N|         138|         141|           1|       26.5| 4.25|    0.5|       7.6|        6.55|                  0.3|        45.7|                 2.5|       1.25|\n",
      "|       2| 2021-12-01 00:29:07|  2021-12-01 00:45:13|            2.0|         2.76|       1.0|                 N|         238|          42|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.8|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+\n",
      "|DOLocationID|average_tip_percentage|\n",
      "+------------+----------------------+\n",
      "|          52|   0.13507571291857495|\n",
      "|          40|    0.1349902504372998|\n",
      "|         255|   0.13294293712786734|\n",
      "|         138|   0.13097318414425485|\n",
      "|         249|    0.1305343050804773|\n",
      "+------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# tip percentage by drop location\n",
    "\n",
    "df = df.withColumn(\"tip_percentage\", col(\"tip_amount\") / col(\"total_amount\"))\n",
    "\n",
    "df_avg_tip = df.groupBy(\"DOLocationID\") \\\n",
    "    .agg(avg(\"tip_percentage\").alias(\"average_tip_percentage\")) \\\n",
    "    .orderBy(\"average_tip_percentage\", ascending=False)\n",
    "\n",
    "# Show the results\n",
    "df_avg_tip.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+\n",
      "|PULocationID|average_tip_percentage|\n",
      "+------------+----------------------+\n",
      "|         255|   0.13022838297171588|\n",
      "|         249|   0.12950151760556006|\n",
      "|         158|   0.12867509846430827|\n",
      "|         199|   0.12681086193114427|\n",
      "|         125|   0.12679905291940308|\n",
      "+------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# tip percentage by pickup location\n",
    "\n",
    "df_avg_tip = df.groupBy(\"PULocationID\") \\\n",
    "    .agg(avg(\"tip_percentage\").alias(\"average_tip_percentage\")) \\\n",
    "    .orderBy(\"average_tip_percentage\", ascending=False)\n",
    "\n",
    "# Show the results\n",
    "df_avg_tip.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n",
      "|trip_distance|average_tip_percentage|\n",
      "+-------------+----------------------+\n",
      "|        59.28|     0.683073832245103|\n",
      "|     29707.75|    0.5571030640668524|\n",
      "|      6206.38|    0.5141388174807198|\n",
      "|        78.29|                   0.5|\n",
      "|        427.7|   0.49748734950270457|\n",
      "+-------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"trip_distance\") \\\n",
    "    .agg(avg(\"tip_percentage\").alias(\"average_tip_percentage\")) \\\n",
    "    .orderBy(\"average_tip_percentage\", ascending=False) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips by time\n",
    "- time of day\n",
    "- day\n",
    "- week\n",
    "- year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|hour|average_tip_amount|\n",
      "+----+------------------+\n",
      "|  23|2.5983358158722796|\n",
      "|  22|2.5913331085310247|\n",
      "|  21|2.5033740848759414|\n",
      "|  20| 2.401028250796292|\n",
      "|  19|2.3693319152925376|\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, hour, avg, dayofmonth, dayofweek, dayofyear, avg, col, expr\n",
    "\n",
    "df.groupBy(hour(\"tpep_pickup_datetime\").alias(\"hour\")) \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip_amount\")) \\\n",
    "    .orderBy(\"hour\", ascending=[False, True]) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|day|average_tip_amount|\n",
      "+---+------------------+\n",
      "|  7|2.3031583344450977|\n",
      "|  6|2.3545071417337415|\n",
      "|  5|2.3668346014951807|\n",
      "|  4| 2.301123499816944|\n",
      "|  3|2.2775269698276484|\n",
      "+---+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(dayofweek(\"tpep_pickup_datetime\").alias(\"day\")) \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip_amount\")) \\\n",
    "    .orderBy((\"day\"), ascending = False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time of day\n",
    "from pyspark.sql.functions import month, hour, avg, dayofmonth, dayofweek, dayofyear, year\n",
    "\n",
    "df_hour = df.groupBy(hour(\"tpep_pickup_datetime\").alias(\"hour\")) \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip_amount\")) \\\n",
    "    .orderBy(\"hour\", ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day\n",
    "df_day = df.groupBy(dayofweek(\"tpep_pickup_datetime\").alias(\"day\")) \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip_amount\")) \\\n",
    "    .orderBy((\"day\"), ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month\n",
    "df_month = df.groupBy(month(\"tpep_pickup_datetime\").alias(\"month\")) \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip_amount\")) \\\n",
    "    .orderBy((\"month\"), ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year\n",
    "df_year = df.groupBy(year(\"tpep_pickup_datetime\").alias(\"year\")) \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip_amount\")) \\\n",
    "    .orderBy((\"year\"), ascending = False) \\\n",
    "    .where(\"year < 2025 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Payment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|     tip_percentage|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------+\n",
      "|       1| 2021-12-01 00:19:51|  2021-12-01 00:37:01|            1.0|          9.3|       1.0|                 N|         138|         141|           1|       26.5| 4.25|    0.5|       7.6|        6.55|                  0.3|        45.7|                 2.5|       1.25|0.16630196936542668|\n",
      "|       2| 2021-12-01 00:29:07|  2021-12-01 00:45:13|            2.0|         2.76|       1.0|                 N|         238|          42|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.8|                 2.5|        0.0|                0.0|\n",
      "|       1| 2021-12-01 00:12:40|  2021-12-01 00:27:17|            0.0|          3.4|       1.0|                 N|         239|          74|           1|       13.5|  3.0|    0.5|       2.0|         0.0|                  0.3|        19.3|                 2.5|        0.0|0.10362694300518134|\n",
      "|       1| 2021-12-01 00:10:18|  2021-12-01 00:19:20|            1.0|          1.3|       1.0|                 N|         148|          87|           1|        6.5|  3.0|    0.5|      2.05|         0.0|                  0.3|       12.35|                 2.5|        0.0|0.16599190283400808|\n",
      "|       1| 2021-12-01 00:25:12|  2021-12-01 00:39:07|            1.0|          3.1|       1.0|                 N|         231|         246|           1|       12.5|  3.0|    0.5|       2.5|         0.0|                  0.3|        18.8|                 2.5|        0.0|0.13297872340425532|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|payment_type|         average_tip|\n",
      "+------------+--------------------+\n",
      "|           1|  3.0755510306720333|\n",
      "|           0|  2.1700068168216124|\n",
      "|           4|0.022958282745690756|\n",
      "|           2|4.108590704647676E-4|\n",
      "|           5|                 0.0|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"payment_type\") \\\n",
    "    .agg(avg(\"tip_amount\").alias(\"average_tip\")) \\\n",
    "    .orderBy(\"average_tip\", ascending=False) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avg Fare by pickup and drop location\n",
    "- Avg fare by passenger count\n",
    "- Fare amount and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|     tip_percentage|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------+\n",
      "|       1| 2021-12-01 00:19:51|  2021-12-01 00:37:01|            1.0|          9.3|       1.0|                 N|         138|         141|           1|       26.5| 4.25|    0.5|       7.6|        6.55|                  0.3|        45.7|                 2.5|       1.25|0.16630196936542668|\n",
      "|       2| 2021-12-01 00:29:07|  2021-12-01 00:45:13|            2.0|         2.76|       1.0|                 N|         238|          42|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        16.8|                 2.5|        0.0|                0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|PULocationID|average_fare_amount|\n",
      "+------------+-------------------+\n",
      "|          44|  99.34643231114435|\n",
      "|          84|  90.55050847457628|\n",
      "|         110|               84.5|\n",
      "|         204|  83.64895833333334|\n",
      "|          99|  82.19200000000001|\n",
      "+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pick up\n",
    "df.groupBy(\"PULocationID\") \\\n",
    "    .agg(avg(\"fare_amount\").alias(\"average_fare_amount\")) \\\n",
    "    .orderBy((\"average_fare_amount\"), ascending = False) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|DOLocationID|average_fare_amount|\n",
      "+------------+-------------------+\n",
      "|          44|  93.73268292682927|\n",
      "|          84|  81.05751937984495|\n",
      "|         204|  78.87132450331126|\n",
      "|           5|  75.44233918128654|\n",
      "|         265|  72.63122658480091|\n",
      "+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop\n",
    "df.groupBy(\"DOLocationID\") \\\n",
    "    .agg(avg(\"fare_amount\").alias(\"average_fare_amount\")) \\\n",
    "    .orderBy((\"average_fare_amount\"), ascending = False) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|passenger_count|average_fare_amount|\n",
      "+---------------+-------------------+\n",
      "|            9.0|              61.35|\n",
      "|            7.0|  52.91679487179488|\n",
      "|            8.0|  49.14408163265307|\n",
      "|            4.0| 14.284687986716266|\n",
      "|            2.0|  13.77639929394148|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# passenger\n",
    "df.groupBy(\"passenger_count\") \\\n",
    "    .agg(avg(\"fare_amount\").alias(\"average_fare_amount\")) \\\n",
    "    .orderBy((\"average_fare_amount\"), ascending = False) \\\n",
    "    .where(\"passenger_count is not null\") \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|trip_distance|average_fare_amount|\n",
      "+-------------+-------------------+\n",
      "|       964.27|             2413.0|\n",
      "|       821.54|             2056.0|\n",
      "|       709.88|             1217.0|\n",
      "|        427.7|             1128.5|\n",
      "|       243.33|             1043.5|\n",
      "|        633.8|             1025.0|\n",
      "|       344.88|              864.5|\n",
      "|        323.0|              823.0|\n",
      "|        271.4|              808.5|\n",
      "|       207.13|              800.0|\n",
      "|       215.95|              800.0|\n",
      "|       165.99|              790.0|\n",
      "|       153.84|              749.5|\n",
      "|        260.5|              722.0|\n",
      "|        282.1|              716.0|\n",
      "|        267.7|              708.0|\n",
      "|       110.17|              701.0|\n",
      "|        270.2|              688.5|\n",
      "|       258.98|              653.0|\n",
      "|       247.37|              620.5|\n",
      "+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# trip distance\n",
    "df.groupBy(\"trip_distance\") \\\n",
    "    .agg(avg(\"fare_amount\").alias(\"average_fare_amount\")) \\\n",
    "    .orderBy((\"average_fare_amount\"), ascending = False) \\\n",
    "    .show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Demand Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:31:38 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "24/05/22 16:31:40 WARN Instrumentation: [b0afd75d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/05/22 16:31:41 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/22 16:31:41 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/05/22 16:31:41 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 2923598.772192168\n",
      "Root Mean Squared Error (RMSE) on test data = 1709.8534358804466\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, hour, dayofweek, count, year, month, dayofmonth\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NYC Taxi Data Analysis\").getOrCreate()\n",
    "\n",
    "folder_path = DATA_DIR  # Placeholder path\n",
    "parquet_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.parquet')]\n",
    "\n",
    "df = spark.read.parquet(*parquet_files)\n",
    "df = df.withColumn(\"hour_of_day\", hour(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_month\", dayofmonth(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"month\", month(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"year\", year(\"tpep_pickup_datetime\"))\n",
    "df_grouped = df.groupBy(\"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\").agg(count(\"*\").alias(\"num_pickups\"))\n",
    "\n",
    "feature_columns = [\"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"num_pickups\")\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "(trainingData, testData) = df_grouped.randomSplit([0.7, 0.3])\n",
    "\n",
    "model = pipeline.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "results = predictions.select(\"prediction\", \"num_pickups\", \"features\")\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"num_pickups\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE) on test data =\", mse)\n",
    "\n",
    "evaluator = evaluator.setMetricName(\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data =\", rmse)\n",
    "\n",
    "#comments\n",
    "# This code snippet performs the following actions:\n",
    "# - It initializes a Spark session and loads the dataset.\n",
    "# - It extracts the hour of the day and the day of the week from the pickup datetime.\n",
    "# - It aggregates the data to count the number of pickups per hour and day of the week.\n",
    "# - It prepares the features for the model using `VectorAssembler`.\n",
    "# - It initializes and trains a linear regression model using a pipeline.\n",
    "# - It makes predictions on the test data and displays 5 example rows of predictions.\n",
    "# - It evaluates the model by calculating the MSE and RMSE on the test data and prints these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+--------------------+\n",
      "|        prediction|num_pickups|            features|\n",
      "+------------------+-----------+--------------------+\n",
      "|2146.6412291762754|       3669|[0.0,1.0,6.0,6.0,...|\n",
      "|2456.1554286690625|       5103|[0.0,1.0,10.0,10....|\n",
      "|  2447.44968864824|       4895|[0.0,1.0,17.0,10....|\n",
      "|  2489.31817780362|       3413|[0.0,1.0,19.0,12....|\n",
      "| 2468.257706044099|       5547|[0.0,1.0,21.0,11....|\n",
      "+------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 966031.1114618272\n",
      "Root Mean Squared Error (RMSE) on test data = 982.8688170156927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, hour, dayofweek, count, year, month, dayofmonth\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import os\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"NYC Taxi Data Analysis\").getOrCreate()\n",
    "\n",
    "# Define folder path and read parquet files\n",
    "folder_path = DATA_DIR # Placeholder path\n",
    "parquet_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.parquet')]\n",
    "\n",
    "df = spark.read.parquet(*parquet_files)\n",
    "\n",
    "# Add time-related columns\n",
    "df = df.withColumn(\"hour_of_day\", hour(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_month\", dayofmonth(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"month\", month(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"year\", year(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Aggregate data\n",
    "df_grouped = df.groupBy(\"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\").agg(count(\"*\").alias(\"num_pickups\"))\n",
    "\n",
    "# Prepare features for the model\n",
    "feature_columns = [\"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Initialize and configure Random Forest regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"num_pickups\", numTrees=100)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Split data into training and test sets\n",
    "(trainingData, testData) = df_grouped.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"num_pickups\", \"features\").show(5)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"num_pickups\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE) on test data =\", mse)\n",
    "\n",
    "evaluator = evaluator.setMetricName(\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data =\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:31:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:31:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:31:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:31:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:31:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:31:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:31:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:22 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+--------------------+\n",
      "|        prediction|num_pickups|            features|\n",
      "+------------------+-----------+--------------------+\n",
      "|1.0630748484046644|          1|[0.0,6.0,1.0,1.0,...|\n",
      "|1.0630748484046644|          1|[0.0,6.0,1.0,1.0,...|\n",
      "|1.0630748484046644|          1|[0.0,6.0,1.0,1.0,...|\n",
      "|1.0630748484046644|          1|[0.0,6.0,1.0,1.0,...|\n",
      "|1.0630748484046644|          1|[0.0,6.0,1.0,1.0,...|\n",
      "+------------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:32:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:32:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:33:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:33:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:33:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 1.76210127791547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:33:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:33:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:33:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:33:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 146:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.3274416288166762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, hour, dayofweek, count, year, month, dayofmonth, lag\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import os\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"NYC Taxi Data Analysis\").getOrCreate()\n",
    "\n",
    "# Define folder path and read parquet files\n",
    "folder_path = DATA_DIR # Placeholder path\n",
    "parquet_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.parquet')]\n",
    "\n",
    "df = spark.read.parquet(*parquet_files)\n",
    "\n",
    "# Add time-related columns\n",
    "df = df.withColumn(\"hour_of_day\", hour(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_month\", dayofmonth(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"month\", month(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"year\", year(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Aggregate data\n",
    "df_grouped = df.groupBy(\"tpep_pickup_datetime\", \"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\").agg(count(\"*\").alias(\"num_pickups\"))\n",
    "\n",
    "# Create lag features\n",
    "windowSpec = Window.orderBy(\"tpep_pickup_datetime\")\n",
    "df_grouped = df_grouped.withColumn(\"lag_1\", lag(\"num_pickups\", 1).over(windowSpec))\n",
    "df_grouped = df_grouped.withColumn(\"lag_2\", lag(\"num_pickups\", 2).over(windowSpec))\n",
    "\n",
    "# Drop null values created by lag\n",
    "df_grouped = df_grouped.na.drop()\n",
    "\n",
    "# Prepare features for the model\n",
    "feature_columns = [\"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\", \"lag_1\", \"lag_2\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Initialize and configure Random Forest regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"num_pickups\", numTrees=100)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Ensure time-based split for training and test sets\n",
    "# For example, use data from 2019-2020 for training and 2021 for testing\n",
    "train_df = df_grouped.filter(col(\"year\") < 2021)\n",
    "test_df = df_grouped.filter(col(\"year\") == 2021)\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_df)\n",
    "predictions.select(\"prediction\", \"num_pickups\", \"features\").show(5)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"num_pickups\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE) on test data =\", mse)\n",
    "\n",
    "evaluator = evaluator.setMetricName(\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data =\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:19 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 148:=============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+------------+-----+----+-----------+\n",
      "|tpep_pickup_datetime|hour_of_day|day_of_week|day_of_month|month|year|num_pickups|\n",
      "+--------------------+-----------+-----------+------------+-----+----+-----------+\n",
      "| 2021-12-01 00:41:51|          0|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 00:39:27|          0|          4|           1|   12|2021|          1|\n",
      "| 2021-11-30 23:57:51|         23|          3|          30|   11|2021|          2|\n",
      "| 2021-12-01 00:47:27|          0|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 00:34:56|          0|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 00:12:54|          0|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 01:31:43|          1|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 01:56:26|          1|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 01:08:14|          1|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 01:18:53|          1|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 02:19:09|          2|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 02:21:23|          2|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 02:34:32|          2|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 02:20:53|          2|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 03:26:54|          3|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 03:36:45|          3|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 04:16:46|          4|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 04:48:14|          4|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 04:09:12|          4|          4|           1|   12|2021|          1|\n",
      "| 2021-12-01 05:51:05|          5|          4|           1|   12|2021|          2|\n",
      "+--------------------+-----------+-----------+------------+-----+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(*parquet_files)\n",
    "\n",
    "# Add time-related columns\n",
    "df = df.withColumn(\"hour_of_day\", hour(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"day_of_month\", dayofmonth(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"month\", month(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"year\", year(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Aggregate data\n",
    "df_grouped = df.groupBy(\"tpep_pickup_datetime\", \"hour_of_day\", \"day_of_week\", \"day_of_month\", \"month\", \"year\").agg(count(\"*\").alias(\"num_pickups\"))\n",
    "\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 16:37:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:37:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:37:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/22 16:37:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:37:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:37:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/05/22 16:37:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 156:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+------------+-----+----+-----------+-----+-----+\n",
      "|tpep_pickup_datetime|hour_of_day|day_of_week|day_of_month|month|year|num_pickups|lag_1|lag_2|\n",
      "+--------------------+-----------+-----------+------------+-----+----+-----------+-----+-----+\n",
      "| 2002-12-31 23:07:20|         23|          3|          31|   12|2002|          1| null| null|\n",
      "| 2003-01-01 00:26:16|          0|          4|           1|    1|2003|          1|    1| null|\n",
      "| 2003-01-01 00:43:37|          0|          4|           1|    1|2003|          1|    1|    1|\n",
      "| 2003-01-01 01:21:25|          1|          4|           1|    1|2003|          1|    1|    1|\n",
      "| 2003-01-01 01:32:47|          1|          4|           1|    1|2003|          1|    1|    1|\n",
      "| 2003-01-03 12:54:36|         12|          6|           3|    1|2003|          1|    1|    1|\n",
      "| 2003-01-05 07:23:34|          7|          1|           5|    1|2003|          1|    1|    1|\n",
      "| 2003-01-05 23:37:05|         23|          1|           5|    1|2003|          1|    1|    1|\n",
      "| 2003-01-09 07:54:48|          7|          5|           9|    1|2003|          1|    1|    1|\n",
      "| 2003-01-23 02:25:38|          2|          5|          23|    1|2003|          1|    1|    1|\n",
      "| 2003-01-29 08:34:30|          8|          4|          29|    1|2003|          1|    1|    1|\n",
      "| 2004-04-04 04:08:30|          4|          1|           4|    4|2004|          1|    1|    1|\n",
      "| 2008-12-31 00:00:00|          0|          4|          31|   12|2008|          1|    1|    1|\n",
      "| 2008-12-31 16:15:09|         16|          4|          31|   12|2008|          1|    1|    1|\n",
      "| 2008-12-31 22:05:53|         22|          4|          31|   12|2008|          1|    1|    1|\n",
      "| 2008-12-31 22:09:02|         22|          4|          31|   12|2008|          1|    1|    1|\n",
      "| 2008-12-31 22:53:48|         22|          4|          31|   12|2008|          1|    1|    1|\n",
      "| 2008-12-31 22:57:07|         22|          4|          31|   12|2008|          2|    1|    1|\n",
      "| 2008-12-31 22:59:12|         22|          4|          31|   12|2008|          1|    2|    1|\n",
      "| 2008-12-31 23:01:52|         23|          4|          31|   12|2008|          1|    1|    2|\n",
      "+--------------------+-----------+-----------+------------+-----+----+-----------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create lag features\n",
    "windowSpec = Window.orderBy(\"tpep_pickup_datetime\")\n",
    "df_grouped = df_grouped.withColumn(\"lag_1\", lag(\"num_pickups\", 1).over(windowSpec))\n",
    "df_grouped = df_grouped.withColumn(\"lag_2\", lag(\"num_pickups\", 2).over(windowSpec))\n",
    "\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "section-3-bis-lhpOOtOo-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
